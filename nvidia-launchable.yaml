name: SAP HANA Cloud LangChain Integration with GPU Acceleration
version: 1.3.0
organization: plturrell
collection: sap-enhanced
description: Enterprise-ready solution for SAP HANA Cloud vector store operations with NVIDIA GPU acceleration, TensorRT optimization, interactive 3D visualizations, and precision vector similarity scoring
runtimeEnvironment: vm
 
license: Apache-2.0
maintainer: plturrell@github.com
supportContact: support@example.com
supportUrl: https://github.com/plturrell/langchain-integration-for-sap-hana-cloud/issues

# NGC Blueprint compatibility metadata
compatibility:
  ngc:
    blueprint: true
    minDriverVersion: "520.0"
    cuda: ">=11.8"
    tensorrt: ">=8.6.0"
    frameworks:
      - pytorch: ">=2.0.0"
      - transformers: ">=4.30.0"

container:
  image: nvcr.io/plturrell/sap-enhanced/langchain-hana-gpu:latest

labels:
  - langchain
  - sap-hana
  - vector-store
  - gpu-acceleration
  - tensorrt
  - embeddings
  - large-language-models
  - context-aware-error-handling
  - enterprise-ready
  - advanced-visualization
  - vector-similarity
  - knowledge-graph

components:
  - name: api-server
    type: service
    container:
      image: nvcr.io/plturrell/sap-enhanced/langchain-hana-gpu:latest
      ports:
        - containerPort: 8000
          protocol: TCP
          # Local port only, no internet exposure required
          expose: false
      env:
        - name: GPU_ENABLED
          value: "true"
        - name: USE_TENSORRT
          value: "true"
        - name: TENSORRT_PRECISION
          value: "fp16"
        - name: ENABLE_CONTEXT_AWARE_ERRORS
          value: "true"
        - name: ENABLE_PRECISE_SIMILARITY
          value: "true"
      volumes:
        - name: trt-engines
          mountPath: /app/trt_engines
          hostPath: /opt/nvidia/trt_engines
    resources:
      gpu:
        required: true
        count: 1
        productFamily: ["Tesla", "Quadro", "RTX", "A100", "H100", "A10", "A30", "A40", "T4"]
        memory: 16Gi
        recommendedModels:
          - name: "NVIDIA T4"
            description: "Cost-effective inference GPU"
            memory: "16GB"
            performance: "Good for small to medium workloads"
          - name: "NVIDIA A10"
            description: "Mid-range inference GPU"
            memory: "24GB"
            performance: "Excellent for medium to large workloads"
          - name: "NVIDIA A100"
            description: "High-end data center GPU"
            memory: "40GB/80GB"
            performance: "Best for high-throughput production workloads"
      memory:
        min: 8Gi
        recommended: 16Gi
      cpu:
        min: 4
        recommended: 8
      storage:
        min: 20Gi
        recommended: 50Gi
        
  - name: frontend
    type: service
    container:
      image: nvcr.io/plturrell/sap-enhanced/langchain-hana-frontend:latest
      ports:
        - containerPort: 3000
          protocol: TCP
          expose: true
    resources:
      memory:
        min: 2Gi
        recommended: 4Gi
      cpu:
        min: 2
        recommended: 4

documentation:
  overview: |
    # SAP HANA Cloud LangChain Integration with GPU Acceleration
    
    This enterprise-ready application provides GPU-accelerated vector operations for SAP HANA Cloud, 
    enabling efficient semantic search and retrieval with LLM-powered embeddings, context-aware 
    error handling, and precision vector similarity scoring.
    
    ## Key Features
    
    - TensorRT optimization for maximum inference speed
    - Multi-GPU load balancing for high throughput
    - Dynamic batch sizing based on GPU memory
    - Memory optimization for large operations
    - Comprehensive benchmarking tools
    - Context-aware error handling with intelligent suggestions
    - Operation-specific error diagnosis and troubleshooting
    - Precise vector similarity measurements for better ranking
    - Sophisticated normalization for consistent scoring
    - Knowledge graph integration via SPARQL
    - Advanced vector visualization with real-time filtering
  
  quickStart: |
    ## Quick Start
    
    ### Step 1: Authenticate with NGC
    
    ```bash
    # Install NGC CLI
    wget -O ngccli.zip https://ngc.nvidia.com/downloads/ngccli_linux.zip
    unzip -o ngccli.zip
    chmod u+x ngc-cli/ngc
    echo 'export PATH="$PATH:$HOME/ngc-cli"' >> ~/.bashrc
    source ~/.bashrc
    
    # Configure NGC CLI with your API key (get it from https://ngc.nvidia.com/setup/api-key)
    ngc config set
    
    # Log in to Docker with NGC credentials
    docker login nvcr.io
    ```
    
    ### Step 2: Pull the container
    
    ```bash
    docker pull nvcr.io/plturrell/sap-enhanced/langchain-hana-gpu:latest
    ```
    
    ### Step 3: Configure SAP HANA Cloud connection
    
    ```bash
    # Create .env file with your credentials
    cat > .env << EOL
    HANA_HOST=your-hana-host.hanacloud.ondemand.com
    HANA_PORT=443
    HANA_USER=your_username
    HANA_PASSWORD=your_password
    ENABLE_CONTEXT_AWARE_ERRORS=true
    ENABLE_PRECISE_SIMILARITY=true
    EOL
    ```
    
    ### Step 4: Run with GPU support
    
    ```bash
    docker run --gpus all -p 8000:8000 \
      --env-file .env \
      -e GPU_ENABLED=true \
      -e USE_TENSORRT=true \
      -e TENSORRT_PRECISION=fp16 \
      nvcr.io/plturrell/sap-enhanced/langchain-hana-gpu:latest
    ```
    
    ### Step 5: Start the frontend
    
    ```bash
    docker run -p 3000:3000 \
      -e REACT_APP_API_URL=http://localhost:8000 \
      nvcr.io/plturrell/sap-enhanced/langchain-hana-frontend:latest
    ```
    
    ### Step 6: Access the application
    
    - Frontend UI: http://localhost:3000
    - API documentation: http://localhost:8000/docs
    - GPU information: http://localhost:8000/benchmark/gpu_info
    - Benchmarking: http://localhost:8000/benchmark/tensorrt
    - Error Documentation: http://localhost:8000/docs/error-handling
    
    For complete setup instructions, refer to the VM Setup Guide.
  
  performance: |
    ## Performance
    
    This solution leverages NVIDIA GPUs to accelerate embedding generation and vector operations:
    
    - TensorRT optimization provides up to 3x faster inference compared to standard PyTorch
    - FP16 precision on Ampere GPUs delivers optimal performance-accuracy balance
    - Dynamic batch sizing automatically adjusts for maximum throughput
    - Multi-GPU scaling shows near-linear performance improvement
    
    ### Benchmarking
    
    Run the built-in benchmark:
    ```bash
    curl -X POST "http://localhost:8000/benchmark/tensorrt" \
      -H "Content-Type: application/json" \
      -d '{
        "model_name": "all-MiniLM-L6-v2",
        "precision": "fp16",
        "batch_sizes": [1, 8, 32, 64, 128],
        "input_length": 128,
        "iterations": 100
      }'
    ```

requirements:
  gpu:
    cuda: ">=11.8"
    driver: ">=520.0"
    tensorRT: ">=8.6.0"
  software:
    docker: ">=20.10.0"
    nvidia-container-toolkit: ">=1.14.0"

environment:
  variables:
    # SAP HANA Cloud Connection Settings
    - name: HANA_HOST
      description: SAP HANA Cloud host
      required: true
      category: "Connection"
      
    - name: HANA_PORT
      description: SAP HANA Cloud port
      required: true
      defaultValue: "443"
      category: "Connection"
      
    - name: HANA_USER
      description: SAP HANA Cloud username
      required: true
      category: "Connection"
      
    - name: HANA_PASSWORD
      description: SAP HANA Cloud password
      required: true
      category: "Connection"
      
    - name: DB_MAX_CONNECTIONS
      description: Maximum number of database connections
      required: false
      defaultValue: "5"
      category: "Connection"
      
    - name: DB_CONNECTION_TIMEOUT
      description: Database connection timeout in seconds
      required: false
      defaultValue: "600"
      category: "Connection"
      
    # GPU Acceleration Settings
    - name: GPU_ENABLED
      description: Enable GPU acceleration
      required: false
      defaultValue: "true"
      category: "GPU"
      
    - name: USE_TENSORRT
      description: Enable TensorRT optimization
      required: false
      defaultValue: "true"
      category: "GPU"
      
    - name: TENSORRT_PRECISION
      description: TensorRT precision (fp16, fp32, int8)
      required: false
      defaultValue: "fp16"
      category: "GPU"
      options: ["fp16", "fp32", "int8"]
      
    - name: TENSORRT_ENGINE_CACHE_DIR
      description: Directory to cache compiled TensorRT engines
      required: false
      defaultValue: "/app/trt_engines"
      category: "GPU"
      
    - name: BATCH_SIZE
      description: Default batch size for embedding operations
      required: false
      defaultValue: "32"
      category: "GPU"
      
    - name: MAX_BATCH_SIZE
      description: Maximum batch size for embedding operations
      required: false
      defaultValue: "128"
      category: "GPU"
      
    - name: ENABLE_MULTI_GPU
      description: Enable multiple GPU support
      required: false
      defaultValue: "true"
      category: "GPU"
      
    # Error Handling Settings
    - name: ENABLE_CONTEXT_AWARE_ERRORS
      description: Enable intelligent error handling with suggestions
      required: false
      defaultValue: "true"
      category: "Error Handling"
      
    - name: ERROR_VERBOSITY
      description: Level of detail in error messages (basic, standard, detailed)
      required: false
      defaultValue: "standard"
      category: "Error Handling"
      options: ["basic", "standard", "detailed"]
      
    - name: ENABLE_ERROR_TELEMETRY
      description: Enable error tracking and telemetry
      required: false
      defaultValue: "true"
      category: "Error Handling"
      
    # Embedding and Vector Settings
    - name: ENABLE_PRECISE_SIMILARITY
      description: Enable accurate vector similarity measurements
      required: false
      defaultValue: "true"
      category: "Vector Operations"
      
    - name: DEFAULT_EMBEDDING_MODEL
      description: Default embedding model to use
      required: false
      defaultValue: "sentence-transformers/all-MiniLM-L6-v2"
      category: "Vector Operations"
      
    - name: DEFAULT_TABLE_NAME
      description: Default vector table name in SAP HANA Cloud
      required: false
      defaultValue: "EMBEDDINGS"
      category: "Vector Operations"
      
    - name: ENABLE_VECTOR_VISUALIZATION
      description: Enable interactive 3D vector visualization
      required: false
      defaultValue: "true"
      category: "Visualization"
      
    # API Settings
    - name: ENABLE_CORS
      description: Enable CORS support
      required: false
      defaultValue: "true"
      category: "API"
      
    - name: CORS_ORIGINS
      description: Allowed CORS origins (comma-separated)
      required: false
      defaultValue: "*"
      category: "API"
      
    - name: JWT_SECRET
      description: Secret for JWT authentication
      required: false
      defaultValue: "sap-hana-langchain-integration-secret-key"
      category: "API"
      
    - name: LOG_LEVEL
      description: Logging level
      required: false
      defaultValue: "INFO"
      category: "API"
      options: ["DEBUG", "INFO", "WARNING", "ERROR"]

relatedSolutions:
  - name: NVIDIA NeMo
    url: https://developer.nvidia.com/nemo
  - name: NVIDIA TensorRT
    url: https://developer.nvidia.com/tensorrt
  - name: LangChain
    url: https://www.langchain.com/
  - name: NVIDIA RAG
    url: https://www.nvidia.com/en-us/research/generative-ai/rag/
  - name: SAP HANA Cloud Vector Engine
    url: https://www.sap.com/products/technology-platform/hana/cloud.html